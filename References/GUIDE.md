# CHOCCY优化器使用指南

## 目录
1. [简介](#简介)
2. [安装](#安装)
3. [背景知识](#背景知识)
4. [算法介绍](#算法介绍)
5. [快速开始](#快速开始)
6. [进阶功能](#进阶功能)
7. [高级功能](#高级功能)
8. [常见问题](#常见问题)
9. [技术支持](#技术支持)

---

## 简介
CHOCCY是一个基于 NumPy 构建的启发式优化求解器，用于解决各种优化问题。<br>
它提供了多种优化算法与问题，支持自定义问题的求解，并支持自定义算法的扩展。<br>
本指南旨在帮助用户快速了解和使用优化器。无论您是初学者还是高级用户，都可以在这里找到所需的信息。

## 安装
### 环境要求
- Python 3.7 或更高版本
- `numpy`、`scipy`、`matplotlib`、`seaborn`、`tqdm`、`networkx` 等依赖包

### 安装步骤
**1. 建议使用 `Anaconda` 创建 `Python` 环境**

  使用 Anaconda 创建环境可以方便地管理依赖包，避免版本冲突。建议从 [Anaconda 官网](https://www.anaconda.com/download/success) 下载并安装 Anaconda。如果需要特定版本，可以访问 [Anaconda所有版本下载地址](https://repo.anaconda.com/archive/)。

  安装完成后，运行以下命令创建 Python 环境：

  ```bash
  conda create --name my_env python=3.9
  conda activate my_env
  ```
  **注意**：本项目支持 Python 3.7 及以上版本，建议使用 Python 3.9 以获得最佳兼容性。

**2. 安装必要包**

  本项目依赖以下包: `numpy`、`scipy`、`matplotlib`、`seaborn`、`tqdm`、`networkx`、`numba`、`tbb`。请确保已安装 Python 3.7 或更高版本，运行以下命令一键安装必要包：

  ```bash
  pip install numpy scipy matplotlib seaborn tqdm networkx numba tbb
  ```

**3. 安装可选包**

  本项目支持通过`numba`进行加速优化。为了体验更快的运行和优化速度，建议安装 `numba` 和 `tbb`。安装命令如下：
  ```bash
  pip install numba tbb
  ```

**4. 镜像源选择**

  如果在运行安装命令时发现下载速度较慢，可以尝试使用清华大学的镜像源进行安装。安装命令如下：
  ```bash
  pip install numpy scipy matplotlib seaborn tqdm networkx numba tbb -i https://pypi.tuna.tsinghua.edu.cn/simple
  ```
  注意：如果无法访问上述镜像源，也可以选择其他可用的镜像源，例如中国科技大学、阿里云等。

## 背景知识
**在使用本项目求解问题之前，需要先熟悉一些背景知识**

### 决策向量/决策变量
决策向量可以理解为需要优化函数的自变量。假设要优化的函数为$y=f(x)$，那么其对应的决策向量为$x$。然而，实际情况下，决策向量通常是多个决策变量的组合。从数学角度来看，要优化的函数更准确的表达应为$y=f(\vec{x})$，其中$\vec{x}=(x_1, x_2, ..., x_n)$。也就是说，该决策向量是一个$n$维向量，换句话说，该决策向量包含$n$个决策变量。

### 目标函数
目标函数实际上就是需要优化的函数。为了统一优化方向，通常将其设定为最小化函数。例如，假设我们要优化（最小化）的函数是$y=f(x)=x^2$，我们都知道该函数在$x=0$时取得最小值$y=0$，这个过程可以通过计算导函数在$x=0$处取得的极小值，并与可能存在的多个极小值进行比较来得到（假如某函数还存在其他极小值的话），当然，其他求最小值的方法（比如梯度下降方法）也能得到这个结果。然而，对于一些复杂的函数，它们可能无法求导数/梯度，或者求导数/梯度的过程非常困难，那么就需要使用其他的方法（比如“启发式/元启发式”方法）来求最小值。另外，需要注意的是，由于决策向量，也就是输入的自变量，可能是多维的。以给出的例子为例，要最小化的函数就变为了$f(\vec{x})=\vec{x}^T\vec{x}$（即向量的平方和），该函数在$\vec{x}=(x_1, x_2, ..., x_n)=(0, 0, ..., 0)$时取得最小值。

### 多目标函数
在了解到目标函数的输入自变量，即决策向量可能是多维的之后，一个自然的延伸问题是：目标函数的输出变量，是否也可能是多维的向量呢？ 如果真是这样，那么目标函数就变为了多目标函数，换句话说，函数的输出可能是多个值，而我们需要同时对这几个值进行优化。

实际上，在大多数情况下，“多目标函数”是由多个目标函数组合而成的。举一个简单的例子：$y=f(x)=\{f_1(x), f_2(x)\} = \{x^2, x^2 + 1\}$，该函数是一个多目标函数，但它非常特殊。在这个例子中，当$x=0$时，两个函数都能同时取得最小值。换句话说，两个函数之间不存在任何“冲突”。这种情况下，同时优化两个函数似乎失去了意义，因为只要优化其中一个就能得到最小值。从狭义上严格来说，这种问题并不算是真正的多目标问题，因为它可以通过加权和的形式转换为单目标问题，优化得到的结果是一致的。

然而，严格来说，真正的多目标函数往往存在某种“冲突”，例如：$y=f(x)=\{f_1(x), f_2(x)\} = \{x^2, (x - 2)^2\}$。

<img src="./Pictures/MOP1.png" style="zoom:45%;" />

在这个例子中，最优解是$x=[0, 2]$整个区间。因为在该区间中，随着一个目标的优化，另一个目标会变差。因此，无法找到一个最优的单个解，最终得到的解是一个区间。这个区间在目标空间中的状态被称为帕累托最优前沿(pareto front)。

<img src="./Pictures/MOP1_PF.png" style="zoom:45%;" />

其实，在生活中存在着许多典型的多目标问题。例如“投资回报问题”，该问题存在的冲突是“风险”与“收益”。一般来说，风险越高，收益越低，反之亦然。当然，多目标问题并不局限于双目标，还有三目标、甚至更多目标的情况。比如，在个人的人生规划中，通常会追求事业目标、家庭目标和个人兴趣目标。这三个目标相互交织，彼此影响，并存在潜在的冲突，例如，过度追求事业目标可能会牺牲与家人相处的时间，而过度投入个人兴趣则可能面临经济压力。因此，我们需要根据自己的价值观和优先级，找到一个相对平衡的解决方案。这种多目标决策过程在我们的生活中无处不在，无论是在个人生活、职业发展还是社会决策中，都需要我们不断地进行权衡和优化。

### 约束函数

除了目标函数以外，实际问题中往往还存在一定的约束条件。拿前面举的例子为例，假设我们要优化的函数是$f(x)=x^2$，约束函数是$g(x)=x-3\geq0$，那么该函数从原来的在$x=0$时取得最小值$y=0$，变为了在$x=3$时取得最小值$y=9$。然而，在实际问题中，约束函数可能会非常复杂，并且还可能存在“等式约束”的情况。

实际上，一般的元启发式算法并不擅长求解带有约束的优化问题，只有在求解较简单的约束时效果尚可。尤其是在存在强约束的情况下，即受到约束后搜索空间非常狭窄，问题会变得更加困难，尤其是当约束中包含“等式约束”时。狭窄的搜索空间会导致元启发式算法在初始化阶段随机生成的解很可能不满足约束条件，甚至全部都不满足约束。这可能会导致搜索过程中大量的计算资源被浪费在优化满足约束条件的解上，从而导致收敛缓慢。因此，通常需要设计专门用于处理约束的算法，例如通过每次修复解以满足约束条件等方法，从而使算法能够更好地向最优目标收敛。

### 评价指标

评价指标是衡量算法对某个问题优化效果的关键工具，尤其是在多目标问题中，其重要性不言而喻。对于多目标问题，常见的评价指标包括：

1. 超体积指标 (HV)
2. 代际距离指标 (GD)
3. 逆代际距离指标 (IGD)
4. 代际距离+指标 (GD+)
5. 逆代际距离+指标 (IGD+) 等

值得注意的是，在真实世界的多目标问题中，Pareto最优前沿通常是未知的。因此，我们通常通过给定参考点，使用超体积指标来进行评价。以下是超体积指标的定义：

**超体积指标 (HV)** 是一种衡量多目标优化算法性能的重要指标，它表示由非支配解集和参考点围成的超体积大小。具体来说，超体积指标反映了优化解集在目标空间中所覆盖的区域大小。超体积越大，说明解集的多样性和接近性越好，优化效果也更佳。其计算公式为：
$$
HV = \text{Volume}(\{y \in \mathbb{R}^m \mid y \succ \text{参考点}, y \prec \text{非支配解集}\})
$$
其中，$\succ$ 表示优于，$\prec$ 表示劣于。超体积指标不仅考虑了解集的分布，还反映了其与参考点的相对位置，是评估多目标优化算法性能的有力工具。

## 算法介绍

### 多目标算法

多目标算法用于求解多目标问题，旨在同时优化多个目标函数。常见的效果较好且通用性强的多目标算法一般是元启发式方法，例如多目标进化算法(遗传算法)，本项目仅支持此类多目标算法，具体支持的算法清单可参见[实现清单](./IMPLES.md)


### 单目标算法
单目标算法用于求解单目标问题，只能优化单个目标函数，本项目仅支持启发式或元启发式的单目标算法，包括但不限于遗传算法、模拟退火算法、粒子群算法、蚁群算法、贪心算法、局部搜索算法等。具体支持的算法清单可参见[实现清单](./IMPLES.md)


## 快速开始

### 问题定义与实现

在使用优化器求解问题之前，需要先明确问题的关键信息，以便正确实现问题。这些关键信息包括：

1. **问题的类型**：即属于`实数`、`整数`、`序列`、`(固定)标签`问题中的哪一种或哪几种
2. **决策变量的个数**：即决策向量的维度
3. **优化目标的个数**：即目标向量的维度
4. **决策变量下界**：即每个决策变量能取得的最小值
5. **决策变量上界**：即每个决策变量能取得的最大值

这些关键信息对应于问题实现中的重要参数：`problem_type`、`num_dec`、`num_obj`、`lower`、`upper`

以一个简单的问题为例，假设要求解的问题是$f(\vec{x})=\vec{x}^T\vec{x}$（即向量的平方和），我们可以确定该问题的关键信息如下：

1. **问题的类型**：该问题是单纯的`实数`问题
2. **决策变量的个数**：不确定，但可以指定，默认为 30
3. **优化目标的个数**：只有单个目标
4. **决策变量下界**：不确定，但为了缩小范围，均指定为 -100
5. **决策变量上界**：不确定，但为了缩小范围，均指定为 100

在确定问题信息时需要注意以下几点：
- 由于给出的例子是特殊的，最终结果是求和，因此决策变量的个数可以不确定。但通常情况下，具体问题的决策变量个数是确定的。
- 对于决策变量的上下界，建议在确定问题信息时大致估算一个数值范围，该范围应尽可能包含函数的最优解。

根据上述信息，可以得到实现该问题的关键参数：
- `problem_type=real`
- `num_dec=30`
- `num_obj=1`
- `lower=-100`
- `upper=100`

在确定好问题的关键信息之后，我们就可以根据这些信息初始化问题类了。所有的问题类都必须继承自 `Problems` 模块下的 `PROBLEM` 父类，这样可以方便后续的预处理和算法调用。

以下是示例代码：

```python
from Problems import PROBLEM

class Sphere(PROBLEM):
    def __init__(self, num_dec=30, lower=-100, upper=100):
        super().__init__(problem_type=PROBLEM.REAL, num_dec=num_dec, num_obj=1, lower=lower, upper=upper)
```
在上述代码中，需要注意三个参数：
1. **`problem_type`参数**
   
    该参数可以直接调用父类 `PROBLEM` 下的静态变量作为输入，也可以直接输入对应的整数值。具体每种问题类型对应的变量值如下：
    ```python
    REAL = 0  # 实数
    INT = 1  # 整数
    BIN = 2  # 二进制
    PMU = 3  # 序列
    FIX = 4  # 固定标签
    ```
    此外，`problem_type` 参数还可以通过输入 `np.array` 数组来指定每一位决策变量的类型。例如，假设输入为：
    ```python
    problem_type=np.array([0, 0, 1, 2])
    ```
    或者：
    ```python
    problem_type=np.array([PROBLEM.REAL, PROBLEM.REAL, PROBLEM.INT, PROBLEM.BIN])
    ```
    那么，输入的决策变量的每一位对应的类型分别为：【`实数`、`实数`、`整数`、`二进制`】。需要注意的是，当输入是 `np.array` 数组时，数组的大小必须与决策变量的个数 `num_dec` 相匹配。
    
2. **`lower`和`upper`参数**

   这两个参数与 `problem_type` 参数类似。当输入单独的值时，指定的是所有决策变量的统一下界和上界。也可以通过输入 `np.array` 来指定每一位决策变量的下界和上界，但数组的大小必须与决策变量的个数 `num_dec` 相匹配。

在初始化问题之后，必须实现问题的目标函数。为此，可以通过覆写 `_cal_obj` 或 `_cal_objs` 中的任意一个方法来完成目标函数的实现。两者的区别在于：`_cal_obj` 用于针对单个解计算目标值，而 `_cal_objs` 则用于批量计算多个解的目标值。

以下是一个覆写 `_cal_obj` 方法的示例：

```python
def _cal_obj(self, x):
    return sum(x ** 2)
```

如果仅覆写了 `_cal_obj` 方法，`PROBLEM` 父类会自动通过 `for` 循环逐次调用 `_cal_obj` 来计算多个解的目标值。其源码实现如下：

```python
import numpy as np

def _cal_objs(self, X):
    """计算整个种群变量的目标值(建议覆写)"""
    pop_size = len(X)
    objs = np.zeros((pop_size, self.num_obj))
    for i in range(pop_size):
        objs[i] = self._cal_obj(X[i])
    return objs
```

虽然这种实现方式在逻辑上没有问题，但运行效率可能较低。为了突破 Python 中 `for` 循环的效率瓶颈，推荐覆写 `_cal_objs` 方法，并利用 `Numpy` 的矩阵操作来计算目标值，这样计算效率会更高。以下是直接使用矩阵操作实现目标值计算的示例代码：

```python
import numpy as np

def _cal_objs(self, X):
    objs = np.sum(X**2, axis=1)
    return objs
```

此外，需要注意的是，输入的 `X` 变量一定是一个二维矩阵。即使决策变量的个数为 `1`，输入的形状也应为 `(n, 1)`，其中 `n` 表示解的个数。

另外，如果将问题定义在了 `Problems` 模块中，建议根据问题的性质将其分类为多目标问题（`Multi`）和单目标问题（`Single`），并将它们分别放入对应的模块文件夹中。同时，建议在模块的 `__init__.py` 文件中导入这些定义，以便于后续的调用。

### 算法选择与调用
定义好问题之后，需要选择一个或多个合适的算法进行求解，具体算法适用求解问题类型可见[算法介绍](#算法介绍)。

对于前面定义的`Sphere`问题，我们可以直接调用合适的单目标算法来求解，以差分进化算法为例：

```python
import numpy as np
from Problems import PROBLEM
from Algorithms import View
from Algorithms.Single import DE

class Sphere(PROBLEM):
    """定义问题"""
    def __init__(self, num_dec=30, lower=-100, upper=100):
        num_obj = 1
        super().__init__(PROBLEM.REAL, num_dec, num_obj, lower, upper)
        
    def _cal_objs(self, X):
        objs = np.sum(X**2, axis=1)
        return objs
    
if __name__ == '__main__':
    problem = Sphere(num_dec=10)  # 实例化问题，并指定决策向量大小
    # 实例化算法并设置种群大小为100，迭代次数为100，优化过程展示为目标值变化情况
    algorithm = DE(pop_size=100, max_iter=100, show_mode=View.OBJ)
    algorithm.solve(problem)  # 使用该算法求解问题
    # 获取最优解并打印
    best, best_obj, best_con = algorithm.get_best()
    print("最优解：", best)
    print("最优解的目标值：", best_obj)
    print("算法运行时间(秒)：", algorithm.run_time)
```

运行代码后可以看到优化过程动图，并得到最终结果

### 算法绘图与可视化

本项目提供了灵活的可视化功能，支持在优化过程中绘制状态图像，以及在优化完成后绘制最终状态或指定迭代次数的状态图像。具体可绘制的内容包括以下几种：

1. 不绘制 (NONE)
2. 绘制进度条 (BAR)
3. 绘制目标空间中的状态 (OBJ)
4. 绘制决策空间中的状态 (DEC)
5. 绘制二维的目标空间和决策空间混合状态 (MIX2D)
6. 绘制三维的目标空间和决策空间混合状态 (MIX3D)
7. 绘制分数/指标的状态 (SCORE)
8. 根据问题给定方法绘制图像 (PROB)
9. 根据算法给定方法绘制图像 (ALGO)

这些选项与 `Algorithms` 模块中静态参数类 `View` 的参数一一对应。因此，在每次绘制图像时，建议先导入该类。以下是具体的绘图方式：

1. 若希望在优化过程中实时绘制图像，可在算法定义时直接将 `show_mode` 参数设置为所需的绘制类型。例如：

    ```python
    # 实例化算法并设置种群大小为100，迭代次数为100，优化过程展示为目标值变化情况
    algorithm = DE(pop_size=100, max_iter=100, show_mode=View.OBJ)
    ```

2. 若希望在优化结束后绘制图像，可在算法运行完成后，通过调用算法的 `plot` 函数并指定 `show_mode` 参数来实现。例如：

    ```python
    # 优化结束后绘制决策空间的状态图像
    algorithm.plot(show_mode=View.DEC)
    # 优化结束后绘制目标空间的状态图像"""
    algorithm.plot(show_mode=View.OBJ)
    ```

3. 若希望在优化结束后绘制某次特定迭代的图像，可在算法运行完成后，通过调用 `plot` 函数并指定 `n_iter` 参数来选择迭代次数。例如：

    ```python
    # 优化结束后绘制第30次迭代的决策空间的状态图像
    algorithm.plot(show_mode=View.DEC, n_iter=30)
    # 优化结束后绘制第30次迭代的目标空间的状态图像
    algorithm.plot(show_mode=View.OBJ, n_iter=30)
    ```

在使用绘图功能时，请注意以下几点：

1. `MIX2D` 和 `MIX3D` 用于绘制目标空间和决策空间混合的状态。这些选项对数据维度有严格要求：决策向量维度必须为2，目标向量维度必须为1。其中，`MIX3D` 将两维的决策向量作为 `x` 和 `y` 轴，目标向量作为 `z` 轴，实现三维空间中的绘图；而 `MIX2D` 则是 `MIX3D` 在二维空间中的投影，以等高线形式呈现。

2. `SCORE` 用于绘制分数/指标的状态。对于单目标问题，默认使用适应度值作为分数；对于多目标问题，默认使用超体积（HV）作为分数。由于多目标问题可能存在多种指标，因此可以指定指标类型。指标类型需在算法优化前设置。

    ```python
    problem = ZDT3()  # 定义问题
    # 定义算法，并指定优化过程展示分数值变化情况
    algorithm = NSGAII(pop_size=100, max_iter=100, show_mode=View.SCORE)
    # 设置评价指标分数类型为逆代际距离指标(IGD)
    algorithm.set_score_type('IGD')
    # 使用算法求解问题
    algorithm.solve(problem)
    ```

## 进阶功能

### 多目标问题的定义与实现

与单目标问题的定义方式相似，多目标问题的定义仍然需要明确问题的关键信息。以一个简单的多目标问题为例，假设要求解的问题是 $y=f(x)=\{f_1(x), f_2(x)\} = \{x^2, (x - 2)^2\}$，我们可以确定该问题的关键信息如下：

1. **问题的类型**：该问题是单纯的 `实数` 问题。
2. **决策变量的个数**：1。
3. **优化目标的个数**：2，因为有两个目标。
4. **决策变量下界**：不确定，但为了缩小范围，均指定为 -1000。
5. **决策变量上界**：不确定，但为了缩小范围，均指定为 1000。

根据上述信息，可以得到实现该问题的关键参数：
- `problem_type=real`
- `num_dec=1`
- `num_obj=2`
- `lower=-1000`
- `upper=1000`

在确定好问题的关键信息之后，我们就可以根据这些信息初始化问题类了。所有的问题类都必须继承自 `Problems` 模块下的 `PROBLEM` 父类，这样可以方便后续的预处理和算法调用。

除了这些基础信息之外，多目标问题还要考虑分数指标，以评价算法的优化效果。

对于已知 Pareto 最优前沿的多目标问题，建议指定问题的最优前沿信息，可以覆写 `PROBLEM` 父类下的 `get_optimum` 函数以指定最优前沿信息。若想同时绘制最优前沿的图像，则可以覆写 `PROBLEM` 父类下的 `get_pareto_front`。这里需要注意一点，当绘制三维空间中的 Pareto 前沿图像时，若 Pareto 前沿为空间中的线，则需要扰动后绘制，参见 `DTLZ5` 的实现。

对于未知 Pareto 最优前沿的多目标问题，建议指定问题的参考点信息，以方便算法对超体积指标的计算（超体积指标的定义参见 [评价指标](#评价指标)）。指定参考点信息时可以覆写 `PROBLEM` 父类下的 `get_optimum` 函数，给定参考点的值即可。`get_optimum` 函数本身虽然是获取问题的最优前沿的函数，但为了简化，同时也兼顾接收参考点的信息。因为当最优前沿已知的时候，直接给定最优前沿，算法会自动计算参考点，而当最优前沿未知，则该函数直接用于获取参考点信息。

以下是示例代码：
```python
import numpy as np
from Problems import PROBLEM

class MOP1(PROBLEM):
    def __init__(self, lower=-1e3, upper=1e3):
        num_dec = 1
        num_obj = 2
        super().__init__(PROBLEM.REAL, num_dec, num_obj, lower, upper)

    def _cal_objs(self, X):
        f1 = X ** 2
        f2 = (X - 2) ** 2
        # 将两个目标合并为一个矩阵
        objs = np.column_stack((f1, f2))
        return objs

    def get_optimum(self, N=1000):
        """获取理论最优目标值"""
        optimums = np.zeros((N, 2))
        optimums[:, 0] = np.linspace(0, 4, N)
        optimums[:, 1] = (np.sqrt(optimums[:, 0]) - 2) ** 2
        return optimums

    def get_pareto_front(self, N=1000):
        """获取帕累托最优前沿(以绘图)"""
        return self.get_optimum(N)
```

此外，需要注意的是，输出的的 `objs` 变量一定是一个二维矩阵，形状为 `(n, m)`，其中 `n` 表示解的个数，`m` 表示目标向量的维度（目标的个数）。

### 约束类型问题

待更新

### 比较器功能的使用

待更新

### 评估器功能的使用

待更新

## 高级功能

### 混合类型问题

待更新

### 算法自定义

待更新

## 常见问题
- **问题 1**：为什么遗传算法等元启发式算法对简单函数得到的结果不精确，也就是存在精度？
  - **问题原因**：这是遗传算法等元启发式算法本身的特性，即使是最简单的函数，也存在一些精度上的不准确
  - **解决方案**：对与简单问题，若想让精度准确，请使用其他的算法（比如梯度算法）提高精度。
- **问题 2**：为什么大部分算法对问题优化和求解得到的结果非常不稳定？
  - **问题原因**：由于大部分算法是启发式或元启发式算法，本身具有一定的随机性，所以求解不稳定，
  - **解决方案**：若想让求解稳定，可以使用`np.random.seed`函数指定随机种子以使得求解稳定。
- **问题 3**：在使用Evaluator对算法进行评估时，绘制的小提琴图上下界为什么会不准确？
  - **问题原因**：小提琴图是基于核密度估计绘制的，由于核密度估计的特性，小提琴图的范围可能会超出实际数据的范围。
  - **解决方案**：若想让小提琴图绘制准确，在函数`plot_violin()`中加入参数`cut=0`即可

## 技术支持
如果您在使用过程中遇到任何问题，可随时联系
- 邮箱：wangluchen567@qq.com



